import os
from pathlib import Path

import streamlit as st
from openai import OpenAI

from scripts.retrieve_tfidf import search

# index builder'Ä± subprocess yerine import ederek Ã§aÄŸÄ±rÄ±yoruz
from scripts.build_index_tfidf import build_index


MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # dÃ¼ÅŸÃ¼k maliyet
client = OpenAI()

INDEX_DIR = Path("index")
NEEDED = ["tfidf_vectorizer.pkl", "tfidf_matrix.pkl", "metadata.pkl"]


def ensure_index():
    INDEX_DIR.mkdir(parents=True, exist_ok=True)
    missing = [f for f in NEEDED if not (INDEX_DIR / f).exists()]
    if missing:
        build_index()


def build_context(results, max_chars=6000):
    parts = []
    total = 0
    for r in results:
        header = f"[KAYNAK: {r['source']} | sayfa {r['page']} | skor {r['score']:.4f}]\n"
        body = (r.get("text") or "").strip()
        chunk = header + body + "\n\n"
        if total + len(chunk) > max_chars:
            break
        parts.append(chunk)
        total += len(chunk)
    return "".join(parts).strip()


def ask_gpt(question: str, results):
    context = build_context(results)

    system = (
        "Sen Ä°stanbul Ãœniversitesi Ä°ÅŸletme FakÃ¼ltesi iÃ§in dokÃ¼man tabanlÄ± bir asistan botsun. "
        "Sadece verilen baÄŸlamdan cevap ver. BaÄŸlamda yoksa 'Bu dokÃ¼manlarda net bir madde bulamadÄ±m.' de. "
        "Cevapta mÃ¼mkÃ¼nse madde numarasÄ±/sayfa belirt. KÄ±sa ve net yaz."
    )

    user = f"SORU: {question}\n\nBAÄLAM:\n{context if context else '(boÅŸ)'}"

    resp = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user},
        ],
        temperature=0.1,
    )
    return resp.choices[0].message.content.strip()


def render_debug(results):
    if not st.session_state.get("debug"):
        return
    st.sidebar.write("Top sonuÃ§lar:")
    for r in results[:5]:
        st.sidebar.write(f"{r['score']:.4f} | {r['source']} | s.{r['page']}")
        if r.get("text"):
            st.sidebar.caption(r["text"][:300].replace("\n", " "))
        else:
            st.sidebar.warning("âš ï¸ text alanÄ± boÅŸ/None")


def main():
    st.set_page_config(page_title="Ä°Ãœ Ä°ÅŸletme Bot", page_icon="ğŸ“", layout="centered")
    st.title("ğŸ“ Ä°Ãœ Ä°ÅŸletme DokÃ¼man Botu")
    st.caption("DokÃ¼manlara gÃ¶re cevap verir. Debug moduyla retrievalâ€™Ä± kontrol edebilirsin.")

    st.session_state["debug"] = st.sidebar.checkbox("Debug modu", value=False)
    st.sidebar.write(f"Model: `{MODEL}`")

    # index garanti
    try:
        ensure_index()
    except Exception as e:
        st.error(f"Index oluÅŸturulamadÄ±: {e}")
        st.stop()

    if "messages" not in st.session_state:
        st.session_state.messages = []

    # geÃ§miÅŸi bas
    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.markdown(m["content"])

    q = st.chat_input("Sorunu yazâ€¦")
    if not q:
        return

    st.session_state.messages.append({"role": "user", "content": q})
    with st.chat_message("user"):
        st.markdown(q)

    with st.chat_message("assistant"):
    try:
        results = search(q, top_k=5)
        render_debug(results)

        # ğŸ”‘ EN Ã–NEMLÄ° KISIM: skor eÅŸiÄŸi
        best = max([r["score"] for r in results], default=0.0)

        if best < 0.05:
            answer = "Bu dokÃ¼manlarda sorunuza doÄŸrudan karÅŸÄ±lÄ±k gelen net bir madde bulamadÄ±m."
        else:
            answer = ask_gpt(q, results)

        # kaynaklarÄ± footer olarak gÃ¶ster
        sources = []
        for r in results[:3]:
            sources.append(
                f"- {r['source']} (s.{r['page']}) skor={r['score']:.4f}"
            )

        footer = "\n\n**Kaynaklar (en yakÄ±n eÅŸleÅŸmeler):**\n" + "\n".join(sources)

        st.markdown(answer + footer)
        st.session_state.messages.append(
            {"role": "assistant", "content": answer + footer}
        )

    except Exception as e:
        st.error(f"Hata: {e}")


if __name__ == "__main__":
    main()
